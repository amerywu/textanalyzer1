[extract_instructions]
provider = corpus_text_rank

# options: job
# possible-phrase
# corpus_text_rank
# corpus_lda
# reddit
#

query_type = exclusion_only
# options
#fetch_all
#field_query
# exclusion_only

query_field = analysis_type
#analysis_type
query_value = Gensim_LDA_by_subset_NounPhraseResultsToLinkedDocList
query_exclude_value = ANY SUBJECT*
query_exclude_field = category
#Gensim_LDA_by_subset_NounPhraseResultsToLinkedDocList

all_providers= job
ignore_indices=xdx

[conn_elasticsearch]
#url = host.docker.internal
#url = localhost
#port = 9200
#scheme = http
#auth = false


url = 192.168.0.141
scheme=http
port=9200
auth = true

[pipeline_instructions]
testenv = true
testenv_doc_process_count = 60000
group_testenv = false
group_testenv_list = COMPUTER SCIENCE
#HUMAN RESOURCE MANAGEMENT,EDUCATION,MARKETING,COMPUTER SCIENCE

pipeline_name = _category_prediction_ld
# options:
#_category_prediction
#_category_prediction_ld
#_text_rank
#_job_integrity_analysis
#gensim_lda,
#sklearn_lda,
#gensim_lda_by_subset,
#lda_topic_comparator
#save_as_csv : Pipeline for saving ES data as a CSV.
#_rake
#_group_by_column
#_text_rank

post_process = save_lists_to_file, save_dictionaries_to_file
# options:
#post process for job analysis
#text_rank_output_by_group,rake_output_by_group,noun_phrase_output_by_group,gensim_lda_report_by_subset
#save_lists_to_file,rf_near_miss
#text_rank_output_by_group
#rake_output_by_group
#tfidf_partof_sentence_breakout, This is the post process to update ES after completing sirf_tfidf pipeline
#rake
#page_views_confluence,
#gensim_lda_report,
#gensim_lda_report_by_subset,
#tfidf_log_text_detector,
#gensim_lda_report_topic_similarity,
#save_dictionaries_to_file
#major_analysis
#save_lists_to_file
#none

continue_run = true
run_forever = false

loop_count = 3

[ml_instructions]
#######
# for all gensim lda
######
gensim_lda_topics = 5
gensim_lda_term_per_topic_reporting_count = 12
gensim_lda_report_sentence_level = true

#######
# for  gensim lda only when analyzing data subsets
######
gensim_lda_permitted_term_overlap_across_topics = 2
gensim_lda_topic_similarity_threshold = 3
gensim_top_level_topic_csv = ./resources/flatfiles/lda_topics_toplevel.csv

#######
# for stop word generation
#########
stopword_top_threshold = 0.005
stopword_bottom_threshold = 0.0005
#######
# for text_cleaning
#########
text_fields_to_clean=skills
strip_tags = True
strip_short = False
strip_nonalphanumeric = True
strip_punctuation = True
strip_multispaces = True
strip_stop_phrases = True
split_alphanum = True
convert_to_lower = True

put_cleaned_text_in_analysis_dict = False

#######
# for sub_groups
######
minimum_doc_count = 40

##############
# for scikit corpus preparation
##################

vectorizer_type = tfidf

############
# for scikit RF
###########
rf_test_proportion = 0.2
rf_category = category
#rf_category = group_by

rf_max_features = 4000
rf_near_miss_proportion = 0.10
#######
# for rake
#########
rake_textfield_in_df = skills

######
# for text_rank
#######

text_rank_top_n_rankings = 5

#######
# for df groupby
#########
df_groupby_column=possible-phrase

[local_data]
lda_topics_toplevel_raw  = ./resources/flatfiles/lda_topics_toplevel_raw.csv
lda_topics_by_subset_raw = ./resources/flatfiles/lda_topics_by_subset_raw.csv
aggregated_majors_filepath = ./resources/aggregatedMajors.json
job_to_majors_filepath = ./resources/jobToMajor.json

[job_instructions]
es_file_location = D:\jake\filedump\data_extracted\output_data.csv
output_folder = D:\jake\filedump\data_extracted\reports
stop_list= ./resources/nlp_inputs/SmartStoplist.txt
stop_phrases= ./resources/nlp_inputs/stop_phrases
stop_list_folder= ./resources/nlp_inputs/
output_to_elasticsearch = true

filter_groupby_threshold_type_dynamic = true
filter_groupby_max_threshold_dynamic = 0.8
filter_groupby_min_threshold_dynamic = 0.3
filter_groupby_max_threshold = 500
filter_groupby_min_threshold = 250

filter_category_threshold_type_dynamic = true
filter_category_max_threshold_dynamic = 0.8
filter_category_min_threshold_dynamic = 0.3
filter_category_max_threshold = 500
filter_category_min_threshold = 250



filter_space_include =
#NounPhrase,RakeResults
#lemmatized
filter_space_exclude = lemmatized,RELATED,ANY,RELEVANT,None
#RELATED,ANY,RELEVANT,None
filter_group_include =
filter_group_exclude = RELATED,ANY,RELEVANT,None